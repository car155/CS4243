{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS4243, CW4, Deep Image Classification, Q5\n",
    "### 2022, Amir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nTo run this code on co lab: \\n\\nadd: import os\\n\\nadd: \\nfrom google.colab import drive\\ndrive.mount(\\'/content/gdrive\\')\\n!ls\\n\\nset the directory, e.g.:\\n\"/content/gdrive/MyDrive/ANN/pets_very_small\"\\n\"/content/gdrive/MyDrive/ANN/flst.txt\"\\n\\nflst.txt file should be modified too\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "To run this code on co lab: \n",
    "\n",
    "add: import os\n",
    "\n",
    "add: \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ls\n",
    "\n",
    "set the directory, e.g.:\n",
    "\"/content/gdrive/MyDrive/ANN/pets_very_small\"\n",
    "\"/content/gdrive/MyDrive/ANN/flst.txt\"\n",
    "\n",
    "flst.txt file should be modified too\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just need these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if we have got GPU or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the train and evaluation dataset and directories\n",
    "# train/evaluation directory is pets_very_small \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1042 files belonging to 2 classes.\n",
      "Using 834 files for training.\n",
      "Found 1042 files belonging to 2 classes.\n",
      "Using 208 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (256,256)\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"pets_very_small\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=110,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"pets_very_small\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=110,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# showing the images \\n# \\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(10, 10))\\nfor images, labels in train_ds.take(1):\\n    for i in range(9):\\n        ax = plt.subplot(3, 3, i + 1)\\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\\n        plt.title(int(labels[i]))\\n        plt.axis(\"off\") '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the images \n",
    "# \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation, using horizontal flip, and random rotation \n",
    "# rotation factor is between 0 to 0.1*2pi \n",
    "# \n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# showing the rotated and flipped images that were added to the \\n# original dataset\\n#\\nplt.figure(figsize=(10, 10))\\nfor images, _ in train_ds.take(1):\\n    for i in range(9):\\n        augmented_images = data_augmentation(images)\\n        ax = plt.subplot(3, 3, i + 1)\\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\\n        plt.axis(\"off\")  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the rotated and flipped images that were added to the \n",
    "# original dataset\n",
    "#\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting train and validation datasets via augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_ds = train_ds.map(\n",
    "  lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=16)\n",
    "val_ds = val_ds.prefetch(buffer_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making our deep model: make_model function\n",
    "# basically, it is a deep convolutional netwrok. Structure is very similar with VGG16 and 19\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    activation = \"sigmoid\"\n",
    "    units = 1\n",
    "   \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(25, activation='relu')(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape=image_size + (3,) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling and training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53/53 [==============================] - 45s 817ms/step - loss: 0.7281 - accuracy: 0.5504 - val_loss: 0.6960 - val_accuracy: 0.5048\n",
      "Epoch 2/5\n",
      "53/53 [==============================] - 43s 801ms/step - loss: 0.7072 - accuracy: 0.5480 - val_loss: 0.7021 - val_accuracy: 0.5048\n",
      "Epoch 3/5\n",
      "53/53 [==============================] - 42s 800ms/step - loss: 0.6645 - accuracy: 0.5971 - val_loss: 0.7415 - val_accuracy: 0.5048\n",
      "Epoch 4/5\n",
      "53/53 [==============================] - 43s 809ms/step - loss: 0.6459 - accuracy: 0.6367 - val_loss: 0.8875 - val_accuracy: 0.5048\n",
      "Epoch 5/5\n",
      "53/53 [==============================] - 44s 831ms/step - loss: 0.6397 - accuracy: 0.6367 - val_loss: 1.0200 - val_accuracy: 0.5048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc632483a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, epochs=epochs, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above: the last validation accuracy above, is a good metric \n",
    "# to show your classifier performance \n",
    "# below: testing the classifier with some images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flst = np.loadtxt('flst.txt', dtype=np.character) \n",
    "ddmm = len(flst)\n",
    "tags = np.zeros( (1,ddmm) )\n",
    "tags[:,27:ddmm]= 1\n",
    "tags = np.int8( tags.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'pets_tiny_test/Cat/0.jpg'  is 84.98 percent cat and 15.02 percent dog.\n",
      "b'pets_tiny_test/Cat/1.jpg'  is 85.13 percent cat and 14.87 percent dog.\n",
      "b'pets_tiny_test/Cat/10.jpg'  is 85.03 percent cat and 14.97 percent dog.\n",
      "b'pets_tiny_test/Cat/13.jpg'  is 84.81 percent cat and 15.19 percent dog.\n",
      "b'pets_tiny_test/Cat/14.jpg'  is 85.29 percent cat and 14.71 percent dog.\n",
      "b'pets_tiny_test/Cat/15.jpg'  is 85.09 percent cat and 14.91 percent dog.\n",
      "b'pets_tiny_test/Cat/16.jpg'  is 84.91 percent cat and 15.09 percent dog.\n",
      "b'pets_tiny_test/Cat/17.jpg'  is 85.06 percent cat and 14.94 percent dog.\n",
      "b'pets_tiny_test/Cat/18.jpg'  is 84.98 percent cat and 15.02 percent dog.\n",
      "b'pets_tiny_test/Cat/2.jpg'  is 84.83 percent cat and 15.17 percent dog.\n",
      "b'pets_tiny_test/Cat/20.jpg'  is 84.93 percent cat and 15.07 percent dog.\n",
      "b'pets_tiny_test/Cat/21.jpg'  is 84.81 percent cat and 15.19 percent dog.\n",
      "b'pets_tiny_test/Cat/22.jpg'  is 85.39 percent cat and 14.61 percent dog.\n",
      "b'pets_tiny_test/Cat/24.jpg'  is 84.99 percent cat and 15.01 percent dog.\n",
      "b'pets_tiny_test/Cat/25.jpg'  is 84.92 percent cat and 15.08 percent dog.\n",
      "b'pets_tiny_test/Cat/26.jpg'  is 85.10 percent cat and 14.90 percent dog.\n",
      "b'pets_tiny_test/Cat/27.jpg'  is 85.23 percent cat and 14.77 percent dog.\n",
      "b'pets_tiny_test/Cat/28.jpg'  is 84.94 percent cat and 15.06 percent dog.\n",
      "b'pets_tiny_test/Cat/29.jpg'  is 85.04 percent cat and 14.96 percent dog.\n",
      "b'pets_tiny_test/Cat/3.jpg'  is 84.72 percent cat and 15.28 percent dog.\n",
      "b'pets_tiny_test/Cat/30.jpg'  is 84.77 percent cat and 15.23 percent dog.\n",
      "b'pets_tiny_test/Cat/4.jpg'  is 84.94 percent cat and 15.06 percent dog.\n",
      "b'pets_tiny_test/Cat/5.jpg'  is 84.97 percent cat and 15.03 percent dog.\n",
      "b'pets_tiny_test/Cat/6.jpg'  is 84.76 percent cat and 15.24 percent dog.\n",
      "b'pets_tiny_test/Cat/7.jpg'  is 85.36 percent cat and 14.64 percent dog.\n",
      "b'pets_tiny_test/Cat/8.jpg'  is 85.05 percent cat and 14.95 percent dog.\n",
      "b'pets_tiny_test/Cat/9.jpg'  is 84.92 percent cat and 15.08 percent dog.\n",
      "b'pets_tiny_test/Dog/0.jpg'  is 84.97 percent cat and 15.03 percent dog.\n",
      "b'pets_tiny_test/Dog/1.jpg'  is 85.01 percent cat and 14.99 percent dog.\n",
      "b'pets_tiny_test/Dog/11.jpg'  is 84.75 percent cat and 15.25 percent dog.\n",
      "b'pets_tiny_test/Dog/12.jpg'  is 84.91 percent cat and 15.09 percent dog.\n",
      "b'pets_tiny_test/Dog/14.jpg'  is 84.85 percent cat and 15.15 percent dog.\n",
      "b'pets_tiny_test/Dog/15.jpg'  is 85.19 percent cat and 14.81 percent dog.\n",
      "b'pets_tiny_test/Dog/16.jpg'  is 84.79 percent cat and 15.21 percent dog.\n",
      "b'pets_tiny_test/Dog/17.jpg'  is 84.94 percent cat and 15.06 percent dog.\n",
      "b'pets_tiny_test/Dog/18.jpg'  is 85.20 percent cat and 14.80 percent dog.\n",
      "b'pets_tiny_test/Dog/19.jpg'  is 85.39 percent cat and 14.61 percent dog.\n",
      "b'pets_tiny_test/Dog/20.jpg'  is 84.58 percent cat and 15.42 percent dog.\n",
      "b'pets_tiny_test/Dog/21.jpg'  is 85.00 percent cat and 15.00 percent dog.\n",
      "b'pets_tiny_test/Dog/22.jpg'  is 84.95 percent cat and 15.05 percent dog.\n",
      "b'pets_tiny_test/Dog/23.jpg'  is 84.86 percent cat and 15.14 percent dog.\n",
      "b'pets_tiny_test/Dog/24.jpg'  is 84.84 percent cat and 15.16 percent dog.\n",
      "b'pets_tiny_test/Dog/25.jpg'  is 85.26 percent cat and 14.74 percent dog.\n",
      "b'pets_tiny_test/Dog/26.jpg'  is 84.87 percent cat and 15.13 percent dog.\n",
      "b'pets_tiny_test/Dog/27.jpg'  is 85.21 percent cat and 14.79 percent dog.\n",
      "b'pets_tiny_test/Dog/28.jpg'  is 85.07 percent cat and 14.93 percent dog.\n",
      "b'pets_tiny_test/Dog/29.jpg'  is 84.91 percent cat and 15.09 percent dog.\n",
      "b'pets_tiny_test/Dog/3.jpg'  is 84.99 percent cat and 15.01 percent dog.\n",
      "b'pets_tiny_test/Dog/30.jpg'  is 84.94 percent cat and 15.06 percent dog.\n",
      "b'pets_tiny_test/Dog/31.jpg'  is 85.10 percent cat and 14.90 percent dog.\n",
      "b'pets_tiny_test/Dog/32.jpg'  is 85.10 percent cat and 14.90 percent dog.\n",
      "b'pets_tiny_test/Dog/33.jpg'  is 84.89 percent cat and 15.11 percent dog.\n",
      "b'pets_tiny_test/Dog/34.jpg'  is 84.78 percent cat and 15.22 percent dog.\n",
      "b'pets_tiny_test/Dog/35.jpg'  is 84.97 percent cat and 15.03 percent dog.\n",
      "b'pets_tiny_test/Dog/36.jpg'  is 84.97 percent cat and 15.03 percent dog.\n",
      "b'pets_tiny_test/Dog/38.jpg'  is 84.89 percent cat and 15.11 percent dog.\n",
      "b'pets_tiny_test/Dog/39.jpg'  is 85.10 percent cat and 14.90 percent dog.\n",
      "b'pets_tiny_test/Dog/4.jpg'  is 84.88 percent cat and 15.12 percent dog.\n",
      "b'pets_tiny_test/Dog/5.jpg'  is 85.04 percent cat and 14.96 percent dog.\n",
      "b'pets_tiny_test/Dog/6.jpg'  is 84.87 percent cat and 15.13 percent dog.\n",
      "b'pets_tiny_test/Dog/7.jpg'  is 84.99 percent cat and 15.01 percent dog.\n",
      "b'pets_tiny_test/Dog/8.jpg'  is 84.88 percent cat and 15.12 percent dog.\n",
      "b'pets_tiny_test/Dog/9.jpg'  is 84.91 percent cat and 15.09 percent dog.\n"
     ]
    }
   ],
   "source": [
    "predct = []\n",
    "for i in flst:\n",
    "    img = keras.preprocessing.image.load_img( i , target_size=image_size )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    score = predictions[0]\n",
    "    print( i , \n",
    "        \" is %.2f percent cat and %.2f percent dog.\"\n",
    "        % (100 * (1 - score), 100 * score)\n",
    "    )\n",
    "    predct.append( np.round(score) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct classification = 27  out of  63  means  0.429\n"
     ]
    }
   ],
   "source": [
    "predct = np.int8( np.array(predct) )\n",
    "sscc = np.sum(abs(tags-predct))\n",
    "print('Number of correct classification =' , ddmm-sscc , ' out of ', ddmm , ' means ', round((ddmm-sscc)/ddmm,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('resul_saved1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
